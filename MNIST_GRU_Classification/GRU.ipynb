{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b09b090c",
      "metadata": {
        "id": "b09b090c"
      },
      "source": [
        "# 라이브러리 임포트 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65cb74c",
      "metadata": {
        "id": "d65cb74c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.transforms import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f116f182",
      "metadata": {
        "id": "f116f182"
      },
      "source": [
        "# CUDA 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e33ddcd6",
      "metadata": {
        "id": "e33ddcd6",
        "outputId": "781f82a1-7d24-4ba8-8d2a-e51a1b611713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    cuda = torch.device('cuda')\n",
        "else:\n",
        "    cuda = torch.device('cpu')\n",
        "\n",
        "print(cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c4c277",
      "metadata": {
        "id": "89c4c277",
        "outputId": "58a505cc-6f58-4de1-b800-b5ee3be3537a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4a500f4770>"
            ]
          },
          "execution_count": 539,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(777)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20dd223e",
      "metadata": {
        "id": "20dd223e"
      },
      "source": [
        "# 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a9defa",
      "metadata": {
        "id": "76a9defa"
      },
      "outputs": [],
      "source": [
        "train_trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=0.1307, std=0.3081),\n",
        "])\n",
        "\n",
        "test_trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=0.1307, std=0.3081)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5c0939",
      "metadata": {
        "id": "fa5c0939"
      },
      "outputs": [],
      "source": [
        "train_data = MNIST(root='./data', download=True, train=True, transform=train_trans)\n",
        "test_data = MNIST(root='./data', download=True, train=False, transform=test_trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9edef42",
      "metadata": {
        "id": "a9edef42"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_load = DataLoader(train_data, batch_size, num_workers=2, shuffle=True)\n",
        "test_load = DataLoader(test_data, batch_size, num_workers=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a317b9a5",
      "metadata": {
        "id": "a317b9a5"
      },
      "source": [
        "# GRU Cell을 이용한 RNN 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## single_gru"
      ],
      "metadata": {
        "id": "fqzjEd3DttUu"
      },
      "id": "fqzjEd3DttUu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5cd4d7",
      "metadata": {
        "id": "fe5cd4d7"
      },
      "outputs": [],
      "source": [
        "# GRUCell 구현\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, sequence_length ,hidden_size, layer_size, num_class, batch_size):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.layer = layer_size\n",
        "        self.num_class = num_class\n",
        "\n",
        "        self.seq = sequence_length\n",
        "        self.gru = nn.GRUCell(self.input_size, self.hidden_size*2)\n",
        "        self.fc = nn.Linear(self.hidden_size*2, self.num_class)\n",
        "      \n",
        "        \n",
        "    def forward(self, x, test=False, label=None):\n",
        "        if test == False:\n",
        "            hx = torch.zeros(self.layer, x.size(0), self.hidden_size*2).to('cuda')\n",
        "\n",
        "            hx = hx[0,:,:] # 차원을 줄이기 위해 사용\n",
        "            out = []\n",
        "            for i in range(self.seq):\n",
        "                hx = self.gru(x[:, i ,:], hx) # 입력 size = > (batch_size, input_size) hx = > (batch_size, hidden_size)\n",
        "                out.append(hx)\n",
        "\n",
        "            out = self.fc(out[-1])\n",
        "\n",
        "            return out\n",
        "        else:\n",
        "            hx = torch.zeros(self.layer, x.size(0), self.hidden_size*2).to('cuda')\n",
        "            hx = hx[0,:,:] # 차원을 줄이기 위해 사용\n",
        "            for i in range(self.seq):\n",
        "                hx = self.gru(x[:, i ,:], hx) # 입력 size = > (batch_size, input_size) hx = > (batch_size, hidden_size)\n",
        "                out = self.fc(hx)\n",
        "                pred = out.max(1, keepdim=True)[1]\n",
        "                acc = pred.eq(label.view_as(pred)).sum().item()\n",
        "                if acc == self.batch_size:\n",
        "                    #print(f'time step {i}')\n",
        "                    return out\n",
        "            \n",
        "            return out\n",
        "                \n",
        "                \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multi_gru"
      ],
      "metadata": {
        "id": "NPGzWoStty1C"
      },
      "id": "NPGzWoStty1C"
    },
    {
      "cell_type": "code",
      "source": [
        "# GRUCell 구현\n",
        "class Multi_RNN(nn.Module):\n",
        "    def __init__(self, input_size, sequence_length ,hidden_size, layer_size, num_class, batch_size):\n",
        "        super(Multi_RNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.layer = layer_size\n",
        "        self.num_class = num_class\n",
        "        self.batch_size = batch_size\n",
        "        self.seq = sequence_length\n",
        "        self.gru1 = nn.GRUCell(self.input_size, self.hidden_size)\n",
        "        self.gru2 = nn.GRUCell(self.hidden_size, self.hidden_size*2)\n",
        "        self.gru3 = nn.GRUCell(self.hidden_size*2, self.hidden_size*4)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        self.fc = nn.Linear(self.hidden_size*4, self.num_class)\n",
        "        \n",
        "        \n",
        "    def forward(self, x, test=False, label=None):\n",
        "        if test == False:\n",
        "            hx1 = torch.zeros(x.size(0), self.hidden_size).to('cuda')\n",
        "            hx2 = torch.zeros(x.size(0), self.hidden_size*2).to('cuda')\n",
        "            hx3 = torch.zeros(x.size(0), self.hidden_size*4).to('cuda')\n",
        "            out = []\n",
        "            for i in range(self.seq):\n",
        "                hx1 = self.gru1(x[:, i ,:], hx1) # 입력 size = > (batch_size, input_size) hx = > (batch_size, hidden_size)\n",
        "                hx1 = self.dropout(hx1)\n",
        "                hx2 = self.gru2(hx1, hx2)\n",
        "                hx2 = self.dropout(hx2)\n",
        "                hx3 = self.gru3(hx2, hx3)\n",
        "                \n",
        "                out.append(hx3)\n",
        "\n",
        "            out = self.fc(out[-1])\n",
        "\n",
        "            return out\n",
        "        else:\n",
        "            hx1 = torch.zeros(x.size(0), self.hidden_size).to('cuda')\n",
        "            hx2 = torch.zeros(x.size(0), self.hidden_size*2).to('cuda')\n",
        "            hx3 = torch.zeros(x.size(0), self.hidden_size*4).to('cuda')\n",
        "            out = []\n",
        "            for i in range(self.seq):\n",
        "                hx1 = self.gru1(x[:, i ,:], hx1) # 입력 size = > (batch_size, input_size) hx = > (batch_size, hidden_size)\n",
        "                hx2 = self.gru2(hx1, hx2)\n",
        "                hx3 = self.gru3(hx2, hx3)\n",
        "                out = self.fc(hx3)\n",
        "                pred = out.max(1, keepdim=True)[1]\n",
        "                acc = pred.eq(label.view_as(pred)).sum().item()\n",
        "                if acc == self.batch_size:\n",
        "                    #print(f'time step {i}')\n",
        "                    return out\n",
        "            \n",
        "            return out\n",
        "                "
      ],
      "metadata": {
        "id": "d7v3_3_rt4nQ"
      },
      "id": "d7v3_3_rt4nQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "77af700d",
      "metadata": {
        "id": "77af700d"
      },
      "source": [
        "# 학습 설정 및 모델 객체화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea0f329",
      "metadata": {
        "id": "1ea0f329"
      },
      "outputs": [],
      "source": [
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = RNN(input_size, sequence_length, hidden_size, num_layers, num_classes, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59107490",
      "metadata": {
        "id": "59107490"
      },
      "source": [
        "# 모델 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fb7bf8",
      "metadata": {
        "id": "01fb7bf8"
      },
      "outputs": [],
      "source": [
        "# 평가 함수\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, sample in enumerate(test_loader):\n",
        "            data, label = sample\n",
        "            data = data.reshape(-1, 28, 28)\n",
        "            data = data.to(cuda)\n",
        "            label = label.to(cuda)\n",
        "\n",
        "            output = model(data, True, label)\n",
        "            loss = criterion(output,label)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "\n",
        "        val_loss /= len(test_loader.dataset)\n",
        "        val_acc = (100. * correct) / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6adae2",
      "metadata": {
        "id": "ac6adae2",
        "outputId": "d22df70c-655b-4de8-f645-71a6e1b6c6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1\t Loss : 0.006460\t Acc : 71.205\n",
            "0.00261277726739645 89.56\n",
            "epoch : 2\t Loss : 0.001987\t Acc : 92.355\n",
            "0.0013211830578744412 94.78\n",
            "epoch : 3\t Loss : 0.001182\t Acc : 95.56666666666666\n",
            "0.0008250142117962241 96.83\n",
            "epoch : 4\t Loss : 0.000838\t Acc : 96.90166666666667\n",
            "0.0007529868412762881 97.24\n",
            "epoch : 5\t Loss : 0.000692\t Acc : 97.34333333333333\n",
            "0.0005943833074532449 97.7\n",
            "epoch : 6\t Loss : 0.000575\t Acc : 97.875\n",
            "0.0005340178694576025 97.96\n",
            "epoch : 7\t Loss : 0.000481\t Acc : 98.22666666666667\n",
            "0.0004551753137260675 98.23\n",
            "epoch : 8\t Loss : 0.000449\t Acc : 98.30333333333333\n",
            "0.0005164464157540351 98.05\n",
            "epoch : 9\t Loss : 0.000392\t Acc : 98.485\n",
            "0.0004784300486091524 98.31\n",
            "epoch : 10\t Loss : 0.000334\t Acc : 98.69833333333334\n",
            "0.0004857259118463844 98.33\n",
            "epoch : 11\t Loss : 0.000294\t Acc : 98.87166666666667\n",
            "0.00037787168599897995 98.65\n",
            "epoch : 12\t Loss : 0.000255\t Acc : 98.99333333333334\n",
            "0.00042012152737006545 98.78\n",
            "epoch : 13\t Loss : 0.000237\t Acc : 99.10166666666667\n",
            "0.0003664981432259083 98.65\n",
            "epoch : 14\t Loss : 0.000211\t Acc : 99.22166666666666\n",
            "0.00039530916099902243 98.7\n",
            "epoch : 15\t Loss : 0.000199\t Acc : 99.21833333333333\n",
            "0.00043434252685401587 98.62\n",
            "epoch : 16\t Loss : 0.000193\t Acc : 99.28166666666667\n",
            "0.00040095719161909073 98.82\n",
            "epoch : 17\t Loss : 0.000178\t Acc : 99.29\n",
            "0.0003752326044603251 98.8\n",
            "epoch : 18\t Loss : 0.000150\t Acc : 99.42833333333333\n",
            "0.00038205127011751755 98.74\n",
            "epoch : 19\t Loss : 0.000169\t Acc : 99.32\n",
            "0.00032215329774553536 98.97\n",
            "epoch : 20\t Loss : 0.000137\t Acc : 99.47666666666667\n",
            "0.0003836306640179828 98.88\n",
            "epoch : 21\t Loss : 0.000098\t Acc : 99.64\n",
            "0.0003571653841790976 99.11\n",
            "epoch : 22\t Loss : 0.000097\t Acc : 99.61333333333333\n",
            "0.0004070280176354572 98.91\n",
            "epoch : 23\t Loss : 0.000098\t Acc : 99.615\n",
            "0.0003695065098036139 98.97\n",
            "epoch : 24\t Loss : 0.000091\t Acc : 99.66666666666667\n",
            "0.00038808606726524887 98.98\n",
            "epoch : 25\t Loss : 0.000086\t Acc : 99.67333333333333\n",
            "0.00043735036045618474 98.84\n",
            "epoch : 26\t Loss : 0.000089\t Acc : 99.65666666666667\n",
            "0.000426710422958422 99.02\n",
            "epoch : 27\t Loss : 0.000080\t Acc : 99.7\n",
            "0.0004630439377069706 98.7\n",
            "epoch : 28\t Loss : 0.000089\t Acc : 99.63333333333334\n",
            "0.0004296432390139671 98.96\n",
            "epoch : 29\t Loss : 0.000080\t Acc : 99.67333333333333\n",
            "0.0004962315559714625 98.91\n",
            "epoch : 30\t Loss : 0.000077\t Acc : 99.69166666666666\n",
            "0.0004407101876542583 98.9\n",
            "epoch : 31\t Loss : 0.000043\t Acc : 99.86\n",
            "0.0005486580077566031 98.71\n",
            "epoch : 32\t Loss : 0.000053\t Acc : 99.79166666666667\n",
            "0.00047928690738317526 98.97\n",
            "epoch : 33\t Loss : 0.000044\t Acc : 99.845\n",
            "0.00045384164414244877 99.0\n",
            "epoch : 34\t Loss : 0.000035\t Acc : 99.875\n",
            "0.0005039234998923917 98.97\n",
            "epoch : 35\t Loss : 0.000058\t Acc : 99.79166666666667\n",
            "0.0004777609982149443 99.0\n",
            "epoch : 36\t Loss : 0.000038\t Acc : 99.86666666666666\n",
            "0.0004445318422240234 99.04\n",
            "epoch : 37\t Loss : 0.000043\t Acc : 99.81\n",
            "0.0005369614211580483 98.87\n",
            "epoch : 38\t Loss : 0.000042\t Acc : 99.845\n",
            "0.0006051456692373904 99.04\n",
            "epoch : 39\t Loss : 0.000048\t Acc : 99.8\n",
            "0.0005168473656554852 98.92\n",
            "epoch : 40\t Loss : 0.000042\t Acc : 99.83333333333333\n",
            "0.0005054921322211157 98.88\n",
            "epoch : 41\t Loss : 0.000025\t Acc : 99.90166666666667\n",
            "0.00045938793905224884 99.03\n",
            "epoch : 42\t Loss : 0.000013\t Acc : 99.95166666666667\n",
            "0.0005234533916540385 99.06\n",
            "epoch : 43\t Loss : 0.000031\t Acc : 99.88833333333334\n",
            "0.0005166240953754823 98.9\n",
            "epoch : 44\t Loss : 0.000031\t Acc : 99.865\n",
            "0.0006191626665836338 98.92\n",
            "epoch : 45\t Loss : 0.000029\t Acc : 99.89166666666667\n",
            "0.0005375379317807358 99.01\n",
            "epoch : 46\t Loss : 0.000023\t Acc : 99.915\n",
            "0.0005392521815414512 99.01\n",
            "epoch : 47\t Loss : 0.000023\t Acc : 99.92\n",
            "0.0006253314682893688 98.85\n",
            "epoch : 48\t Loss : 0.000011\t Acc : 99.96\n",
            "0.0005562864994239589 99.03\n",
            "epoch : 49\t Loss : 0.000029\t Acc : 99.90333333333334\n",
            "0.0006236396834246989 98.9\n",
            "epoch : 50\t Loss : 0.000043\t Acc : 99.84833333333333\n",
            "0.0005054540528779853 99.07\n"
          ]
        }
      ],
      "source": [
        "opt = torch.optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)\n",
        "\n",
        "# 미분값이 0에 가까워질수록 학습률을 줄여주기 위해 사용한다. lr에 감마값을 곱해준다.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opt,step_size = 10, gamma = 0.8) \n",
        "criterion = nn.CrossEntropyLoss().to(cuda)\n",
        "model = model.to(cuda)\n",
        "train_acc = []\n",
        "train_loss = []\n",
        "\n",
        "test_acc = []\n",
        "test_loss = []\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "\n",
        "    accuracy = 0\n",
        "    loss_ = 0\n",
        "    \n",
        "    loss_test = 0\n",
        "    accuracy_test = 0\n",
        "\n",
        "    for batch, train in enumerate(train_load):\n",
        "        data, label = train\n",
        "\n",
        "        data = data.reshape(-1, 28, 28)\n",
        "        data = data.to(cuda)\n",
        "        label = label.to(cuda)\n",
        "\n",
        "        out = model(data)\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "\n",
        "        loss_ += loss.item()\n",
        "\n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "\n",
        "        acc = pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy += acc\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        \n",
        "    epoch_loss = loss_ / len(train_load.dataset)\n",
        "    epoch_acc = (100.*accuracy) / len(train_load.dataset)\n",
        "    \n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    \n",
        "    print(f'epoch : {epoch+1}\\t Loss : {epoch_loss:.6f}\\t Acc : {epoch_acc}')\n",
        "    loss_test, accuracy_test = evaluate(model, test_load)\n",
        "    test_loss.append(loss_test)\n",
        "    test_acc.append(accuracy_test)\n",
        "    \n",
        "    print(loss_test, accuracy_test)\n",
        "\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b692e856",
      "metadata": {
        "id": "b692e856",
        "outputId": "addbc536-4ed9-400e-a314-7048293baf8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.0005253338096883453, 98.99)\n"
          ]
        }
      ],
      "source": [
        "print(evaluate(model, test_load))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9bf9d4",
      "metadata": {
        "id": "9b9bf9d4"
      },
      "source": [
        "# GRU 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a24cd09",
      "metadata": {
        "id": "0a24cd09"
      },
      "outputs": [],
      "source": [
        "class RNN2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, layer_size, num_class):\n",
        "        super(RNN2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.layer = layer_size\n",
        "        self.num_class = num_class\n",
        "        \n",
        "        self.gru = nn.GRU(input_size, self.hidden_size*2, self.layer, batch_first=True)\n",
        "        #self.fc = nn.Linear(self.hidden_size, self.num_class)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size*2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        hx = torch.zeros(self.layer, x.size(0), self.hidden_size*2).to('cuda')\n",
        "        out, _ = self.gru(x, hx)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "    \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb7b29d",
      "metadata": {
        "id": "6cb7b29d"
      },
      "source": [
        "# 학습 설정 및 모델 객체화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c881d5b4",
      "metadata": {
        "id": "c881d5b4"
      },
      "outputs": [],
      "source": [
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 1\n",
        "num_classes = 10\n",
        "\n",
        "model = RNN2(input_size, hidden_size, num_layers, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc418fd",
      "metadata": {
        "id": "6fc418fd"
      },
      "source": [
        "# 모델 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc471285",
      "metadata": {
        "id": "bc471285"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, sample in enumerate(test_loader):\n",
        "            data, label = sample\n",
        "            data = data.reshape(-1, 28, 28)\n",
        "            data = data.to(cuda)\n",
        "            label = label.to(cuda)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output,label)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            prediction = output.max(1, keepdim=True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "\n",
        "        val_loss /= len(test_loader.dataset)\n",
        "        val_acc = (100. * correct) / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9cdae4",
      "metadata": {
        "id": "5f9cdae4",
        "outputId": "9b256c90-6a24-4e06-b82d-2016c72d1cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1\t Loss : 0.006663\t Acc : 70.40666666666667\n",
            "0.0024453244104981424 90.91\n",
            "epoch : 2\t Loss : 0.001954\t Acc : 92.89166666666667\n",
            "0.0012103027317672968 95.1\n",
            "epoch : 3\t Loss : 0.001088\t Acc : 96.085\n",
            "0.0007962903561070561 96.98\n",
            "epoch : 4\t Loss : 0.000762\t Acc : 97.275\n",
            "0.0005699967806227505 97.78\n",
            "epoch : 5\t Loss : 0.000600\t Acc : 97.885\n",
            "0.0006052789299050346 98.04\n",
            "epoch : 6\t Loss : 0.000489\t Acc : 98.23666666666666\n",
            "0.0005076343753607944 98.35\n",
            "epoch : 7\t Loss : 0.000420\t Acc : 98.52666666666667\n",
            "0.0005031658638035879 98.25\n",
            "epoch : 8\t Loss : 0.000375\t Acc : 98.66\n",
            "0.0004693086785962805 98.19\n",
            "epoch : 9\t Loss : 0.000329\t Acc : 98.79333333333334\n",
            "0.0004163190145744011 98.51\n",
            "epoch : 10\t Loss : 0.000289\t Acc : 99.015\n",
            "0.00036647669021040204 98.83\n",
            "epoch : 11\t Loss : 0.000225\t Acc : 99.21666666666667\n",
            "0.00036139820822281765 98.79\n",
            "epoch : 12\t Loss : 0.000209\t Acc : 99.235\n",
            "0.000394527717854362 98.73\n",
            "epoch : 13\t Loss : 0.000185\t Acc : 99.305\n",
            "0.0003511115780798718 98.81\n",
            "epoch : 14\t Loss : 0.000174\t Acc : 99.355\n",
            "0.00033542529880069196 99.01\n",
            "epoch : 15\t Loss : 0.000162\t Acc : 99.41166666666666\n",
            "0.00035034345278636464 98.98\n",
            "epoch : 16\t Loss : 0.000155\t Acc : 99.43666666666667\n",
            "0.0004431513165908655 98.62\n",
            "epoch : 17\t Loss : 0.000137\t Acc : 99.47666666666667\n",
            "0.0004015941760131682 98.85\n",
            "epoch : 18\t Loss : 0.000116\t Acc : 99.59166666666667\n",
            "0.00032517778208457457 99.02\n",
            "epoch : 19\t Loss : 0.000120\t Acc : 99.545\n",
            "0.0004294731440139003 98.68\n",
            "epoch : 20\t Loss : 0.000105\t Acc : 99.59833333333333\n",
            "0.0003564858587604249 98.99\n",
            "epoch : 21\t Loss : 0.000086\t Acc : 99.68833333333333\n",
            "0.0004006750471988198 98.86\n",
            "epoch : 22\t Loss : 0.000067\t Acc : 99.77333333333333\n",
            "0.00039718223659338035 98.87\n",
            "epoch : 23\t Loss : 0.000076\t Acc : 99.73833333333333\n",
            "0.0003522999388340395 99.05\n",
            "epoch : 24\t Loss : 0.000074\t Acc : 99.74333333333334\n",
            "0.0003780072893368924 98.96\n",
            "epoch : 25\t Loss : 0.000056\t Acc : 99.81833333333333\n",
            "0.0003526699745667429 99.09\n",
            "epoch : 26\t Loss : 0.000050\t Acc : 99.835\n",
            "0.0004195058616689494 98.95\n",
            "epoch : 27\t Loss : 0.000080\t Acc : 99.73166666666667\n",
            "0.0003545619180180438 98.98\n",
            "epoch : 28\t Loss : 0.000057\t Acc : 99.82166666666667\n",
            "0.0004560409015141886 99.01\n",
            "epoch : 29\t Loss : 0.000057\t Acc : 99.79166666666667\n",
            "0.0004939730365862488 98.88\n",
            "epoch : 30\t Loss : 0.000073\t Acc : 99.73333333333333\n",
            "0.0004630603773985058 98.67\n",
            "epoch : 31\t Loss : 0.000035\t Acc : 99.86333333333333\n",
            "0.00044284521953100013 99.09\n",
            "epoch : 32\t Loss : 0.000024\t Acc : 99.90833333333333\n",
            "0.0004552040214442968 99.1\n",
            "epoch : 33\t Loss : 0.000030\t Acc : 99.89833333333333\n",
            "0.0004437538320304043 99.01\n",
            "epoch : 34\t Loss : 0.000047\t Acc : 99.82\n",
            "0.0004033450733193604 99.06\n",
            "epoch : 35\t Loss : 0.000026\t Acc : 99.905\n",
            "0.00038157474776276103 99.12\n",
            "epoch : 36\t Loss : 0.000010\t Acc : 99.97\n",
            "0.0003929790964791209 99.25\n",
            "epoch : 37\t Loss : 0.000051\t Acc : 99.82666666666667\n",
            "0.00040112362261279485 99.06\n",
            "epoch : 38\t Loss : 0.000039\t Acc : 99.85166666666667\n",
            "0.0004250215968554585 99.06\n",
            "epoch : 39\t Loss : 0.000021\t Acc : 99.93166666666667\n",
            "0.00037891195694764976 99.11\n",
            "epoch : 40\t Loss : 0.000036\t Acc : 99.875\n",
            "0.0004536832615174717 98.99\n",
            "epoch : 41\t Loss : 0.000022\t Acc : 99.925\n",
            "0.00039950630423873007 99.16\n",
            "epoch : 42\t Loss : 0.000012\t Acc : 99.95666666666666\n",
            "0.00039574448932658013 99.23\n",
            "epoch : 43\t Loss : 0.000009\t Acc : 99.98\n",
            "0.0003891181160572728 99.17\n",
            "epoch : 44\t Loss : 0.000016\t Acc : 99.94333333333333\n",
            "0.0004952786618742607 99.04\n",
            "epoch : 45\t Loss : 0.000038\t Acc : 99.875\n",
            "0.0003756747399531349 99.18\n",
            "epoch : 46\t Loss : 0.000033\t Acc : 99.885\n",
            "0.0003934547655952656 99.2\n",
            "epoch : 47\t Loss : 0.000011\t Acc : 99.95666666666666\n",
            "0.0004064722979290764 99.15\n",
            "epoch : 48\t Loss : 0.000025\t Acc : 99.91833333333334\n",
            "0.0004397789855696146 99.05\n",
            "epoch : 49\t Loss : 0.000009\t Acc : 99.95666666666666\n",
            "0.00048110583237106537 99.07\n",
            "epoch : 50\t Loss : 0.000026\t Acc : 99.94166666666666\n",
            "0.0004357078265958627 99.19\n"
          ]
        }
      ],
      "source": [
        "opt = torch.optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)\n",
        "\n",
        "# 미분값이 0에 가까워질수록 학습률을 줄여주기 위해 사용한다. lr에 감마값을 곱해준다.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opt,step_size = 10, gamma = 0.8) \n",
        "criterion = nn.CrossEntropyLoss().to(cuda)\n",
        "model = model.to(cuda)\n",
        "train_acc = []\n",
        "train_loss = []\n",
        "\n",
        "test_acc = []\n",
        "test_loss = []\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "\n",
        "    accuracy = 0\n",
        "    loss_ = 0\n",
        "    \n",
        "    loss_test = 0\n",
        "    accuracy_test = 0\n",
        "\n",
        "    for batch, train in enumerate(train_load):\n",
        "        data, label = train\n",
        "\n",
        "        data = data.reshape(-1, 28, 28)\n",
        "        data = data.to(cuda)\n",
        "        label = label.to(cuda)\n",
        "\n",
        "        out = model(data)\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "\n",
        "        loss_ += loss.item()\n",
        "\n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "\n",
        "        acc = pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy += acc\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        \n",
        "    epoch_loss = loss_ / len(train_load.dataset)\n",
        "    epoch_acc = (100.*accuracy) / len(train_load.dataset)\n",
        "    \n",
        "    train_loss.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    \n",
        "    print(f'epoch : {epoch+1}\\t Loss : {epoch_loss:.6f}\\t Acc : {epoch_acc}')\n",
        "    loss_test, accuracy_test = evaluate(model, test_load)\n",
        "    test_loss.append(loss_test)\n",
        "    test_acc.append(accuracy_test)\n",
        "    \n",
        "    print(loss_test, accuracy_test)\n",
        "\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b68ca46",
      "metadata": {
        "id": "4b68ca46",
        "outputId": "51a8cf5d-0438-4045-d320-ec67b33eb7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0.0004357078284192916, 99.19)\n"
          ]
        }
      ],
      "source": [
        "print(evaluate(model, test_load))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0613f00",
      "metadata": {
        "id": "d0613f00"
      },
      "source": [
        "# 학습과정 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6481a79f",
      "metadata": {
        "id": "6481a79f"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb0986a8",
      "metadata": {
        "id": "cb0986a8",
        "outputId": "b63cfd19-6e33-4b39-9937-7abd1e746760"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_acc, 'b', label='train')\n",
        "plt.plot(test_acc, 'r', label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f161d08",
      "metadata": {
        "id": "4f161d08",
        "outputId": "415b6e10-7866-4680-dca8-9b3bf929f350"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_loss, 'b', label='train')\n",
        "plt.plot(test_loss, 'r', label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}