{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7J7IGqgh4Cg"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8qCWkWllJ3Z"
      },
      "source": [
        "# 이미지 전처리 및 데이터 증대"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxKFMqKuiM5M",
        "outputId": "79aa432e-fc4d-48a9-9a50-c9fba16f1670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_data = CIFAR100(root='./data', download=True, train=True, transform=transforms.ToTensor()) # train_trans를 transform에 넣으면 augmentation 진행\n",
        "test_data = CIFAR100(root='./data', download=True, train=False, transform=transforms.ToTensor()) # test_trans를 transform에 넣으면 augmentation 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ow17BrRdHrKY",
        "outputId": "5209e7bf-8934-4be7-b55a-5d334ba985bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23731\n",
            "(3, 32, 32)\n",
            "(32, 32, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def imshow(img):\n",
        "    show_img = img.numpy()\n",
        "    print(show_img.shape)\n",
        "    plt.imshow(np.transpose(show_img, (1, 2, 0)))\n",
        "    print(np.transpose(show_img, (1, 2, 0)).shape)\n",
        "    plt.show()\n",
        "\n",
        "rand = np.random.randint(len(train_data))\n",
        "print(rand)\n",
        "imshow(train_data[rand][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LygXfcc5l_lQ"
      },
      "source": [
        "tranforms.Normalize [0.5070 0.4865 0.4409] [0.2673 0.2564 0.2761]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data augmentation"
      ],
      "metadata": {
        "id": "xc7__ZrhCVnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvnWQiNLnPtd",
        "outputId": "18346e71-0488-4bff-de53-13638cd9e02a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdfRneVKmD1U",
        "outputId": "6437661c-c3d6-4ee9-ed33-8093bacd0247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[129.30416561 124.0699627  112.43405006] [68.1702429  65.39180804 70.41837019]\n",
            "[0.50707516 0.48654887 0.44091784] [0.26733429 0.25643846 0.27615047]\n"
          ]
        }
      ],
      "source": [
        "train_mean = train_data.data.mean(axis=(0,1,2))\n",
        "train_std = train_data.data.std(axis=(0,1,2))\n",
        "\n",
        "print(train_mean, train_std)\n",
        "\n",
        "train_mean = train_mean / 255\n",
        "train_std = train_std / 255\n",
        "\n",
        "print(train_mean, train_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VRpDu8QoGAB"
      },
      "source": [
        "randomcrop ==>> 이미지를 양쪽에 4픽셀씩 채운 다음 이미지에서 무작위로 32x32로 자름"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YENv2AJPjtCJ"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "test_trans = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_mean, train_std),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkTipIRjjAxy",
        "outputId": "259d8309-5c62-481c-d7b6-f9c445cbbf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train = CIFAR100(root='./data', download=True, train=True, transform=trans)\n",
        "test = CIFAR100(root='./data', download=True, train=False, transform=test_trans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM_gjB3KjFA6"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_load = DataLoader(train, batch_size, num_workers=4, shuffle=True)\n",
        "test_load = DataLoader(test, batch_size, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEessODnJL7o"
      },
      "source": [
        "# CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OgdLGVUJOzk"
      },
      "source": [
        "output size = ((input_size - kernel_size + 2*padding_size) / strides) + 1\n",
        "\n",
        "maxpooling ==>> maxpooling 값으로 나눈 값이 output_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet"
      ],
      "metadata": {
        "id": "SMmVUr8JCLin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    \"\"\"Residual block for resnet over 50 layers\n",
        "    \"\"\"\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels:int, out_channels:int, stride=1):\n",
        "        super().__init__()\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))"
      ],
      "metadata": {
        "id": "vm-TcpzICA7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block:BottleNeck, num_block:list, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block:BottleNeck, out_channels, num_blocks:list, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "K51FgRcaCAUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet50(): #70\n",
        "    \"\"\" return a ResNet 50 object\n",
        "    \"\"\"\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
        "\n",
        "def resnet101():\n",
        "    \"\"\" return a ResNet 101 object\n",
        "    \"\"\"\n",
        "    return ResNet(BottleNeck, [3, 4, 23, 3])\n"
      ],
      "metadata": {
        "id": "F1IdtaT4B_q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## simple CNN"
      ],
      "metadata": {
        "id": "MhbSUla4CCnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28C1GA95ZsJE"
      },
      "outputs": [],
      "source": [
        "# 이미지의 크기가 작기 때문에 적은 합성곱 필터를 적용할 예정이다. \n",
        "# MaxPool ==>> 2\n",
        "# conv ==>> 3\n",
        "# classifier ==>> 3\n",
        "# kernel_size => (3, 3), stride => (1, 1), padding(1, 1)을 줬을 경우 output_size => 입력 이미지 원래 사이즈\n",
        "# MaxPool을 2번 해주기 때문에 합성곱 신경망을 통과하고 나온 이미지의 사이즈 ==>> 8*8\n",
        "# layer_count = [64, 128, 128, 'M', 128, 256, 256, 'M', 256, 512, 512, 'M', 512] ==>> train 99%, model 20 test 70%, 기존 CNN\n",
        "layer_count = [64, 128, 'M', 128, 256, 256, 'M' ,512, 512]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ6zyRvRRATo"
      },
      "outputs": [],
      "source": [
        "def make_conv2d(layer_count:list, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "\n",
        "    for i in layer_count:\n",
        "        if i == 'M':\n",
        "            layers += [nn.MaxPool2d(2)]\n",
        "        else:\n",
        "            layers += [nn.Conv2d(in_channels, i, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(i) ,nn.ReLU()]\n",
        "            in_channels = i\n",
        "            \n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaCmo1wGBTbv"
      },
      "outputs": [],
      "source": [
        "# 새로운 CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, conv_layer, num_classes = 100):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layers = conv_layer\n",
        "        self.fc1 = nn.Linear(512*8*8, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc = nn.Sequential(\n",
        "            self.fc1,\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            self.fc2,\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NW4nGAppatO"
      },
      "outputs": [],
      "source": [
        "# 기존 CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, conv_layer, num_classes = 100):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layers = conv_layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512*8*8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wide Resnet"
      ],
      "metadata": {
        "id": "92L9bpVTDQm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "\n",
        "class wide_basic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
        "        super(wide_basic, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Wide_ResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
        "        super(Wide_ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth-4)/6\n",
        "        k = widen_factor\n",
        "\n",
        "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
        "        nStages = [16, 16*k, 32*k, 64*k]\n",
        "\n",
        "        self.conv1 = conv3x3(3,nStages[0])\n",
        "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
        "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
        "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
        "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "V8iY20KwDO97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 선언"
      ],
      "metadata": {
        "id": "U2Kwr8mrDY4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4V5VgKyqOiv"
      },
      "outputs": [],
      "source": [
        "conv = make_conv2d(layer_count)\n",
        "model = CNN(conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-iJbSLWecpR",
        "outputId": "e440b401-3642-45b2-86a6-cb564d922f28",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): ReLU()\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU()\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "  )\n",
              "  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=32768, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=256, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "U4hPEWlJDc42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-iqi3hDlP6z"
      },
      "outputs": [],
      "source": [
        "# 이전 lr = 0.005\n",
        "opt = torch.optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(opt,step_size = 20, gamma = 0.8) # 미분값이 0에 가까워질수록 학습률을 줄여주기 위해 사용한다. lr에 감마값을 곱해준다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bF_mlMVNsE2",
        "outputId": "71ad4928-f9d3-4071-9b8a-a844bee33823",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1\t Loss : 0.034969\t Acc : 2.438\n",
            "(0.03387265000343323, 3.34)\n",
            "epoch : 2\t Loss : 0.033498\t Acc : 3.298\n",
            "(0.032584723520278934, 5.04)\n",
            "epoch : 3\t Loss : 0.032488\t Acc : 4.252\n",
            "(0.03163637824058533, 6.67)\n",
            "epoch : 4\t Loss : 0.031637\t Acc : 5.374\n",
            "(0.031104162168502807, 8.38)\n",
            "epoch : 5\t Loss : 0.030700\t Acc : 6.692\n",
            "(0.02973010458946228, 10.75)\n",
            "epoch : 6\t Loss : 0.029433\t Acc : 8.806\n",
            "(0.028134243893623352, 14.33)\n",
            "epoch : 7\t Loss : 0.027979\t Acc : 11.18\n",
            "(0.026401351261138916, 16.56)\n",
            "epoch : 8\t Loss : 0.026407\t Acc : 14.194\n",
            "(0.024651342988014222, 20.74)\n",
            "epoch : 9\t Loss : 0.025003\t Acc : 17.184\n",
            "(0.023186781787872316, 25.31)\n",
            "epoch : 10\t Loss : 0.023646\t Acc : 20.332\n",
            "(0.022381568598747254, 26.45)\n",
            "epoch : 11\t Loss : 0.022363\t Acc : 23.64\n",
            "(0.02032767057418823, 32.67)\n",
            "epoch : 12\t Loss : 0.021184\t Acc : 26.308\n",
            "(0.02048557505607605, 32.91)\n",
            "epoch : 13\t Loss : 0.020168\t Acc : 28.986\n",
            "(0.018773107719421388, 37.78)\n",
            "epoch : 14\t Loss : 0.019161\t Acc : 31.95\n",
            "(0.017990202379226685, 39.53)\n",
            "epoch : 15\t Loss : 0.018101\t Acc : 34.572\n",
            "(0.01727932540178299, 40.92)\n",
            "epoch : 16\t Loss : 0.017191\t Acc : 37.42\n",
            "(0.016721134984493256, 42.84)\n",
            "epoch : 17\t Loss : 0.016277\t Acc : 39.742\n",
            "(0.016342898833751677, 43.57)\n",
            "epoch : 18\t Loss : 0.015431\t Acc : 42.448\n",
            "(0.016009788775444032, 44.77)\n",
            "epoch : 19\t Loss : 0.014577\t Acc : 44.964\n",
            "(0.01586827927827835, 45.94)\n",
            "epoch : 20\t Loss : 0.013754\t Acc : 47.32\n",
            "(0.015358949840068817, 46.77)\n",
            "epoch : 21\t Loss : 0.012573\t Acc : 50.82\n",
            "(0.015244195580482484, 48.75)\n",
            "epoch : 22\t Loss : 0.011765\t Acc : 53.368\n",
            "(0.01497067893743515, 49.41)\n",
            "epoch : 23\t Loss : 0.011126\t Acc : 55.43\n",
            "(0.015108955764770508, 49.89)\n",
            "epoch : 24\t Loss : 0.010436\t Acc : 57.54\n",
            "(0.015454057323932648, 49.86)\n",
            "epoch : 25\t Loss : 0.010021\t Acc : 59.22\n",
            "(0.015360030019283294, 50.41)\n",
            "epoch : 26\t Loss : 0.009570\t Acc : 60.75\n",
            "(0.01551087144613266, 50.22)\n",
            "epoch : 27\t Loss : 0.009088\t Acc : 62.74\n",
            "(0.015934104692935942, 50.89)\n",
            "epoch : 28\t Loss : 0.008597\t Acc : 64.62\n",
            "(0.016020173490047456, 50.45)\n",
            "epoch : 29\t Loss : 0.008243\t Acc : 65.86\n",
            "(0.016375387942790986, 51.35)\n",
            "epoch : 30\t Loss : 0.007812\t Acc : 67.576\n",
            "(0.01716236649751663, 50.59)\n",
            "epoch : 31\t Loss : 0.007481\t Acc : 68.652\n",
            "(0.01639966207742691, 51.83)\n",
            "epoch : 32\t Loss : 0.007102\t Acc : 70.314\n",
            "(0.01656459231376648, 52.03)\n",
            "epoch : 33\t Loss : 0.006877\t Acc : 71.022\n",
            "(0.016852285647392273, 51.46)\n",
            "epoch : 34\t Loss : 0.006491\t Acc : 72.512\n",
            "(0.017234803640842438, 52.05)\n",
            "epoch : 35\t Loss : 0.006298\t Acc : 73.458\n",
            "(0.017350081133842468, 52.12)\n",
            "epoch : 36\t Loss : 0.006080\t Acc : 74.432\n",
            "(0.017547868466377257, 52.31)\n",
            "epoch : 37\t Loss : 0.005726\t Acc : 75.84\n",
            "(0.018716627156734465, 51.7)\n",
            "epoch : 38\t Loss : 0.005624\t Acc : 76.416\n",
            "(0.01811544795036316, 51.92)\n",
            "epoch : 39\t Loss : 0.005442\t Acc : 77.064\n",
            "(0.018572780799865723, 52.77)\n",
            "epoch : 40\t Loss : 0.005152\t Acc : 78.302\n",
            "(0.01935840756893158, 52.62)\n",
            "epoch : 41\t Loss : 0.004703\t Acc : 80.062\n",
            "(0.01886383521556854, 53.22)\n",
            "epoch : 42\t Loss : 0.004485\t Acc : 81.078\n",
            "(0.019027196311950684, 53.61)\n",
            "epoch : 43\t Loss : 0.004269\t Acc : 82.032\n",
            "(0.02040783394575119, 53.1)\n",
            "epoch : 44\t Loss : 0.004159\t Acc : 82.5\n",
            "(0.02032545876502991, 53.27)\n",
            "epoch : 45\t Loss : 0.004037\t Acc : 83.148\n",
            "(0.01978035020828247, 53.84)\n",
            "epoch : 46\t Loss : 0.003934\t Acc : 83.444\n",
            "(0.020541085517406462, 53.37)\n",
            "epoch : 47\t Loss : 0.003786\t Acc : 84.006\n",
            "(0.021087548446655273, 53.4)\n",
            "epoch : 48\t Loss : 0.003659\t Acc : 84.708\n",
            "(0.02026623659133911, 53.0)\n",
            "epoch : 49\t Loss : 0.003531\t Acc : 85.118\n",
            "(0.021694193410873412, 53.42)\n",
            "epoch : 50\t Loss : 0.003502\t Acc : 85.216\n",
            "(0.021677744960784912, 53.78)\n",
            "epoch : 51\t Loss : 0.003336\t Acc : 86.182\n",
            "(0.02184048776626587, 53.72)\n",
            "epoch : 52\t Loss : 0.003214\t Acc : 86.746\n",
            "(0.02211751055717468, 54.0)\n",
            "epoch : 53\t Loss : 0.003284\t Acc : 86.306\n",
            "(0.022039995145797728, 53.69)\n",
            "epoch : 54\t Loss : 0.003177\t Acc : 86.956\n",
            "(0.022801214575767517, 53.35)\n",
            "epoch : 55\t Loss : 0.003098\t Acc : 87.186\n",
            "(0.022509690356254577, 53.32)\n",
            "epoch : 56\t Loss : 0.003036\t Acc : 87.32\n",
            "(0.02273573341369629, 53.8)\n",
            "epoch : 57\t Loss : 0.002935\t Acc : 87.79\n",
            "(0.023318580400943756, 53.69)\n",
            "epoch : 58\t Loss : 0.002876\t Acc : 88.19\n",
            "(0.023128951573371886, 53.44)\n",
            "epoch : 59\t Loss : 0.002800\t Acc : 88.334\n",
            "(0.022994828963279725, 53.82)\n",
            "epoch : 60\t Loss : 0.002761\t Acc : 88.506\n",
            "(0.02324284439086914, 53.59)\n",
            "epoch : 61\t Loss : 0.002603\t Acc : 89.214\n",
            "(0.023803895449638367, 53.47)\n",
            "epoch : 62\t Loss : 0.002385\t Acc : 90.084\n",
            "(0.023958185076713562, 54.59)\n",
            "epoch : 63\t Loss : 0.002353\t Acc : 90.594\n",
            "(0.024521338653564453, 54.71)\n",
            "epoch : 64\t Loss : 0.002218\t Acc : 90.894\n",
            "(0.02545116970539093, 54.44)\n",
            "epoch : 65\t Loss : 0.002235\t Acc : 90.71\n",
            "(0.024462942886352538, 54.29)\n",
            "epoch : 66\t Loss : 0.002146\t Acc : 91.2\n",
            "(0.02516577296257019, 54.72)\n",
            "epoch : 67\t Loss : 0.002162\t Acc : 91.122\n",
            "(0.026034243416786194, 54.54)\n",
            "epoch : 68\t Loss : 0.002084\t Acc : 91.494\n",
            "(0.02545229208469391, 54.37)\n",
            "epoch : 69\t Loss : 0.002076\t Acc : 91.658\n",
            "(0.025216001057624816, 54.7)\n",
            "epoch : 70\t Loss : 0.002072\t Acc : 91.542\n",
            "(0.026277990198135377, 54.28)\n",
            "epoch : 71\t Loss : 0.002020\t Acc : 91.63\n",
            "(0.02616021134853363, 54.46)\n",
            "epoch : 72\t Loss : 0.001966\t Acc : 91.9\n",
            "(0.026599523830413817, 54.29)\n",
            "epoch : 73\t Loss : 0.001932\t Acc : 92.146\n",
            "(0.026358790481090546, 54.52)\n",
            "epoch : 74\t Loss : 0.001924\t Acc : 92.19\n",
            "(0.02611390836238861, 54.34)\n",
            "epoch : 75\t Loss : 0.001885\t Acc : 92.13\n",
            "(0.02691166546344757, 54.77)\n",
            "epoch : 76\t Loss : 0.001848\t Acc : 92.452\n",
            "(0.02764777138233185, 54.48)\n",
            "epoch : 77\t Loss : 0.001769\t Acc : 92.674\n",
            "(0.027273075938224794, 54.61)\n",
            "epoch : 78\t Loss : 0.001754\t Acc : 92.838\n",
            "(0.027170327639579772, 54.78)\n",
            "epoch : 79\t Loss : 0.001687\t Acc : 93.156\n",
            "(0.027827856063842773, 54.32)\n",
            "epoch : 80\t Loss : 0.001729\t Acc : 92.98\n",
            "(0.028395519590377807, 53.88)\n",
            "epoch : 81\t Loss : 0.001561\t Acc : 93.728\n",
            "(0.02768834309577942, 54.33)\n",
            "epoch : 82\t Loss : 0.001500\t Acc : 93.844\n",
            "(0.027951424264907838, 54.55)\n",
            "epoch : 83\t Loss : 0.001436\t Acc : 94.118\n",
            "(0.029353762102127076, 54.31)\n",
            "epoch : 84\t Loss : 0.001443\t Acc : 94.052\n",
            "(0.028025576853752135, 54.48)\n",
            "epoch : 85\t Loss : 0.001406\t Acc : 94.334\n",
            "(0.029793881940841673, 54.62)\n",
            "epoch : 86\t Loss : 0.001411\t Acc : 94.23\n",
            "(0.029254350805282592, 54.31)\n",
            "epoch : 87\t Loss : 0.001376\t Acc : 94.616\n",
            "(0.03076574430465698, 54.62)\n",
            "epoch : 88\t Loss : 0.001365\t Acc : 94.54\n",
            "(0.03015359408855438, 54.82)\n",
            "epoch : 89\t Loss : 0.001357\t Acc : 94.582\n",
            "(0.030307242393493652, 54.61)\n",
            "epoch : 90\t Loss : 0.001310\t Acc : 94.742\n",
            "(0.0306458815574646, 55.11)\n",
            "epoch : 91\t Loss : 0.001348\t Acc : 94.632\n",
            "(0.0316063951253891, 54.42)\n",
            "epoch : 92\t Loss : 0.001270\t Acc : 94.812\n",
            "(0.02978417589664459, 55.1)\n",
            "epoch : 93\t Loss : 0.001308\t Acc : 94.832\n",
            "(0.030174712800979615, 54.88)\n",
            "epoch : 94\t Loss : 0.001267\t Acc : 94.932\n",
            "(0.031428077387809755, 54.85)\n",
            "epoch : 95\t Loss : 0.001249\t Acc : 94.974\n",
            "(0.03106387183666229, 54.73)\n",
            "epoch : 96\t Loss : 0.001249\t Acc : 94.96\n",
            "(0.03194899318218231, 54.48)\n",
            "epoch : 97\t Loss : 0.001196\t Acc : 95.116\n",
            "(0.03149995017051697, 54.75)\n",
            "epoch : 98\t Loss : 0.001174\t Acc : 95.31\n",
            "(0.03185348441600799, 54.49)\n",
            "epoch : 99\t Loss : 0.001220\t Acc : 95.162\n",
            "(0.03169854922294617, 54.55)\n",
            "epoch : 100\t Loss : 0.001149\t Acc : 95.324\n",
            "(0.03165260009765625, 54.64)\n"
          ]
        }
      ],
      "source": [
        "train(model, train_load, opt, scheduler, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRlkwvxzgdbI"
      },
      "source": [
        "# 모델의 학습과 평가를 위한 기타 함수들"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew9UfFIxid9V",
        "outputId": "9a6761c4-640b-49c6-9fc9-1e501e603a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "#gpu 사용설정\n",
        "if torch.cuda.is_available():\n",
        "    cuda = torch.device('cuda')\n",
        "else:\n",
        "    cuda = torch.device('cpu')\n",
        "\n",
        "print(cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuvHmtkZf3dA"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred, label):\n",
        "    _, predict = torch.max(pred, dim=1)\n",
        "    print(predict)\n",
        "    return torch.tensor(torch.sum(predict==label).item()/len(predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKmyyZjziN2W"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, opt, scheduler, epochs):\n",
        "    \n",
        "    save_path = '/data/bcw/cifar_models_arg/'\n",
        "    history = []\n",
        "\n",
        "    model = model.to(cuda)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        train_acc = []\n",
        "        train_loss = []\n",
        "        lrs = []\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss().to(cuda)\n",
        "\n",
        "        for batch, train in enumerate(train_loader):\n",
        "            data, label = train\n",
        "\n",
        "            data = data.to(cuda)\n",
        "            label = label.to(cuda)\n",
        "\n",
        "            out = model(data)\n",
        "\n",
        "            loss = criterion(out, label)\n",
        "\n",
        "            train_loss += [loss.item()]\n",
        "\n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "\n",
        "            acc = pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "            train_acc += [acc]\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            #print(f'Batch Size : {batch+1}\\t Loss : {loss.item():.6f}\\t Acc : {100*(acc / len(data))}')\n",
        "    \n",
        "        epoch_loss = sum(train_loss) / len(train_loader.dataset)\n",
        "        epoch_acc = (100.*sum(train_acc)) / len(train_loader.dataset)\n",
        "        print(f'epoch : {epoch+1}\\t Loss : {epoch_loss:.6f}\\t Acc : {epoch_acc}')\n",
        "        print(evaluate(model, test_load))\n",
        "\n",
        "        scheduler.step()\n",
        "        \n",
        "        if (epoch+1) % 10 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'model'+str(epoch+1)+'.pth')\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xnCItgmBTby"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss().to(cuda)\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, sample in enumerate(test_loader):\n",
        "        data, label = sample\n",
        "        data = data.to(cuda)\n",
        "        label = label.to(cuda)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output,label)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        prediction = output.max(1, keepdim=True)[1]\n",
        "        correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "\n",
        "    val_loss /= len(test_loader.dataset)\n",
        "    val_acc = (100. * correct) / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Qd2PXJBTby",
        "outputId": "61b6220a-26c8-4854-bf32-d2aa7ce00221"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.016821904706954955, 63.98)"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(model, test_load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIUqejkXBTbz"
      },
      "outputs": [],
      "source": [
        "conv = make_conv2d(layer_count)\n",
        "model = CNN(conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlR0L46iBTbz",
        "outputId": "3a5e6bed-89c6-4f4e-92c0-aafe61d89e9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (0.025903230500221253, 17.21)\n",
            "2 (0.01662197403907776, 41.5)\n",
            "3 (0.012958569872379302, 54.91)\n",
            "4 (0.011684920001029967, 60.09)\n",
            "5 (0.011192742109298706, 64.44)\n",
            "6 (0.011844787383079529, 65.21)\n",
            "7 (0.012905730533599854, 67.38)\n",
            "8 (0.013626645052433014, 67.34)\n",
            "9 (0.014733218157291412, 68.24)\n",
            "10 (0.015471077477931977, 67.93)\n",
            "11 (0.016741797745227813, 68.42)\n",
            "12 (0.01732672674655914, 68.36)\n",
            "13 (0.017470908224582672, 69.38)\n",
            "14 (0.01810816696882248, 69.34)\n",
            "15 (0.018822974240779878, 69.58)\n",
            "16 (0.019429851138591768, 69.44)\n",
            "17 (0.019690802991390227, 70.07)\n",
            "18 (0.020749757874011992, 69.58)\n",
            "19 (0.021344657588005064, 69.53)\n",
            "20 (0.021324719059467315, 70.19)\n"
          ]
        }
      ],
      "source": [
        "for i in range(20):\n",
        "    conv = make_conv2d(layer_count)\n",
        "    model = CNN(conv)\n",
        "    model.load_state_dict(torch.load(\"cifar_models/model\"+str((i+1)*10)+'.pth'))\n",
        "    model.to(cuda)\n",
        "    print(i+1,evaluate(model, test_load))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYGuAaLLBTbz",
        "outputId": "e2002caa-040f-4778-e18e-d58fc3886780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1])\n",
            "tensor([97, 98, 60, 69, 27, 74, 46, 27, 80, 35, 30, 38, 58, 91,  2, 88, 25, 11,\n",
            "        83, 72, 82, 68, 78,  6, 63, 48, 12, 12,  6, 60, 83, 10, 40, 16, 84, 66,\n",
            "        77, 67, 77, 17, 43, 67, 88, 45, 12, 50, 98, 90, 16,  6, 60,  8, 25, 27,\n",
            "        95, 50, 68, 51, 44, 79, 22, 28, 63, 59, 78, 89,  0, 34, 90, 51,  6, 36,\n",
            "        77, 25, 82, 36, 49, 70, 44, 99, 43, 49, 18, 40, 34, 49, 35,  9, 84, 79,\n",
            "        23, 69, 35, 35, 18, 53, 23,  6, 59, 95, 52, 25, 86,  5, 56, 61, 23, 93,\n",
            "        20, 36,  6, 14, 96, 88, 33, 26, 20,  8, 39, 11, 59, 35, 79, 22, 83,  8,\n",
            "        46, 47])\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "for batch, train in enumerate(train_load):\n",
        "    if batch == 1:\n",
        "        data, label = train\n",
        "\n",
        "        data = data\n",
        "        label = label\n",
        "\n",
        "        out = model(data)\n",
        "\n",
        "        loss = criterion(out, label)\n",
        "\n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "        \n",
        "        print(pred.shape)\n",
        "        print(label)\n",
        "\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3dFqpdABTb0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cifar100_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}